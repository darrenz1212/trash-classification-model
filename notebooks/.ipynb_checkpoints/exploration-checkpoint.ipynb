{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "49f0486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbCallback\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "50b47046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(project=\"trash-classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cc7a0d",
   "metadata": {},
   "source": [
    "## spit dataset (80% train 20% test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "799b90a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263b91cc",
   "metadata": {},
   "source": [
    "spliting the data into seperate folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1ffe6a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2024 images belonging to 6 classes.\n",
      "Found 503 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\User\\Desktop\\trash-classification\\data\\train',  \n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training' \n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\User\\Desktop\\trash-classification\\data\\train',  \n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecd49d0",
   "metadata": {},
   "source": [
    "All image has their own classes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdae9b99",
   "metadata": {},
   "source": [
    "First things first, im using CNN model to train those image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aba38be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 2024\n",
      "Total validation samples: 503\n"
     ]
    }
   ],
   "source": [
    "print(\"Total training samples:\", train_generator.samples)\n",
    "print(\"Total validation samples:\", validation_generator.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8c6970ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "96c27cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ab748508",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f2a74e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 5s/step - accuracy: 0.3063 - loss: 1.6813 - val_accuracy: 0.3479 - val_loss: 1.5735\n",
      "Epoch 2/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 5s/step - accuracy: 0.4111 - loss: 1.4158 - val_accuracy: 0.3678 - val_loss: 1.5130\n",
      "Epoch 3/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 5s/step - accuracy: 0.4857 - loss: 1.2827 - val_accuracy: 0.4195 - val_loss: 1.3972\n",
      "Epoch 4/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 5s/step - accuracy: 0.5477 - loss: 1.1452 - val_accuracy: 0.4314 - val_loss: 1.3053\n",
      "Epoch 5/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 6s/step - accuracy: 0.5786 - loss: 1.1171 - val_accuracy: 0.4930 - val_loss: 1.3489\n",
      "Epoch 6/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 5s/step - accuracy: 0.6337 - loss: 0.9976 - val_accuracy: 0.4533 - val_loss: 1.3423\n",
      "Epoch 7/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 6s/step - accuracy: 0.6189 - loss: 1.0324 - val_accuracy: 0.5209 - val_loss: 1.2999\n",
      "Epoch 8/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 6s/step - accuracy: 0.6558 - loss: 0.9569 - val_accuracy: 0.5288 - val_loss: 1.2621\n",
      "Epoch 9/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 5s/step - accuracy: 0.6233 - loss: 0.9740 - val_accuracy: 0.5288 - val_loss: 1.2571\n",
      "Epoch 10/10\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 5s/step - accuracy: 0.6573 - loss: 0.9442 - val_accuracy: 0.5288 - val_loss: 1.2777\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "#     callbacks=[checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9285c3a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2f8c307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "Dropout(0.25),\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "Dropout(0.25),\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "Dropout(0.25),\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "Dropout(0.5),\n",
    "model.add(Dense(6, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba20d7ac",
   "metadata": {},
   "source": [
    "im using adam as the optimizer this time. (i write the code like this cuz somehow i cant import tensorflow.keras.optimizers.legacy import Adam) :(((((("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "613da174",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "42b4ef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras',\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dc1e7bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94e88b6",
   "metadata": {},
   "source": [
    "Counting step per epoch and validation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2f3ed835",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
    "validation_steps = validation_generator.samples // validation_generator.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659e2199",
   "metadata": {},
   "source": [
    "lets add some more epoch this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5fa452f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 6s/step - accuracy: 0.1822 - loss: 1.9198 - val_accuracy: 0.3500 - val_loss: 1.6214\n",
      "Epoch 2/50\n",
      "\u001b[1m 1/63\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 520ms/step - accuracy: 0.3438 - loss: 1.4995"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - accuracy: 0.3438 - loss: 1.4995 - val_accuracy: 0.3913 - val_loss: 1.5618\n",
      "Epoch 3/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 5s/step - accuracy: 0.3629 - loss: 1.5010 - val_accuracy: 0.3812 - val_loss: 1.5508\n",
      "Epoch 4/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - accuracy: 0.4062 - loss: 1.4129 - val_accuracy: 0.3478 - val_loss: 1.5874\n",
      "Epoch 5/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 5s/step - accuracy: 0.5039 - loss: 1.2554 - val_accuracy: 0.4396 - val_loss: 1.4378\n",
      "Epoch 6/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.5000 - loss: 1.3214 - val_accuracy: 0.3913 - val_loss: 1.3466\n",
      "Epoch 7/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m472s\u001b[0m 7s/step - accuracy: 0.5195 - loss: 1.2113 - val_accuracy: 0.4688 - val_loss: 1.3105\n",
      "Epoch 8/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 128ms/step - accuracy: 0.5625 - loss: 1.2683 - val_accuracy: 0.4783 - val_loss: 1.3701\n",
      "Epoch 9/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 8s/step - accuracy: 0.5651 - loss: 1.1227 - val_accuracy: 0.5000 - val_loss: 1.3518\n",
      "Epoch 10/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 124ms/step - accuracy: 0.6250 - loss: 0.9725 - val_accuracy: 0.5217 - val_loss: 1.2897\n",
      "Epoch 11/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m451s\u001b[0m 6s/step - accuracy: 0.5981 - loss: 1.0461 - val_accuracy: 0.5063 - val_loss: 1.3142\n",
      "Epoch 12/50\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 112ms/step - accuracy: 0.6250 - loss: 1.0495 - val_accuracy: 0.5652 - val_loss: 1.2209\n",
      "Epoch 13/50\n",
      "\u001b[1m23/63\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m4:25\u001b[0m 7s/step - accuracy: 0.6086 - loss: 0.9986"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=50, \n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_steps,\n",
    "#     callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca48b447",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
